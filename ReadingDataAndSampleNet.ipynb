{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from pyteomics import  fasta, parser, mass, achrom, electrochem, auxiliary, mzxml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tsv_data(path):\n",
    "    with open(path) as tsv:\n",
    "        reader = csv.reader(tsv, dialect=\"excel-tab\")\n",
    "        header = next(reader) #skip header\n",
    "        for line in reader:\n",
    "            yield list(zip(header, line))\n",
    "\n",
    "\n",
    "            \n",
    "def get_mzxml_filenames(dir_path):\n",
    "    for mzxml_filepath in glob.glob(f\"{dir_path}/*.mzXML\"):\n",
    "        yield mzxml_filepath\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "('Peptidoform', '.SPLFM+15.995GK.')\n('Peptidoform ID', 'SPLFM+15.995GK')\n('Unmod peptidoform', '.SPLFMGK.')\n('Total', '11679')\n('Total- Unmodified sequence', '11681')\n('Peptidoforms- Unmodified sequence', '2')\n('Proteins', 'sp|P01009|A1AT_HUMAN;tr|A0A024R6I7|A0A024R6I7_HUMAN')\n('Mass', '795.406')\n('Charge', '2')\n('Num Mods', '1')\n('All Mods', ',16,')\n('Is Decoy', 'False')\n('Lorikeet input', 'SPLFM+15.995GK')\n('Orig cluster FDR', '0.000380267')\n('Pep Prefix', 'SP')\n('Annotation', 'M+16,5[Oxidation]')\n('Annotation without position', 'M+16[Oxidation]')\n('Known', 'UNIMOD')\n('Num mod frags', '9')\n('PValue', '4.715')\n('% Explained', '75.1')\n('Rep cluster task', '4e3c96640e534ecdb7053896d6f56f67')\n('Rep cluster user', 'batch')\n('Rep cluster index', '205322')\n('Num tasks', '55')\n('Rep spectrum filename', 'MSV000080596/ccms_peak/RAW/20150708_QEp1_LC7_PhGe_SA_Plate1C_1_4.mzXML')\n('Rep spectrum scan', '10244')\n('Outlier groups', '.Patient-29.Timepoint-4.')\n('Outlier group ratio', '0.17')\n('Outlier groups- unmod', '.Patient-29.Timepoint-4.')\n('Outlier group ratio- unmod', '0.17')\n('Unmod_Peptidoform', 'SPLFMGK')\n('Patient_01.Timepoint_1', '2,173,877,500')\n('Patient_01.Timepoint_1_unmod', '7,105,650,000')\n('Patient_01.Timepoint_2', '2,197,450,000')\n('Patient_01.Timepoint_2_unmod', '7,815,675,000')\n('Patient_01.Timepoint_3', '2,864,495,000')\n('Patient_01.Timepoint_3_unmod', '6,870,275,000')\n('Patient_01.Timepoint_4', '1,613,750,000')\n('Patient_01.Timepoint_4_unmod', '5,074,450,000')\n('Patient_01.Timepoint_5', '2,574,530,000')\n('Patient_01.Timepoint_5_unmod', '9,432,350,000')\n('Patient_01.Timepoint_6', '4,678,075,000')\n('Patient_01.Timepoint_6_unmod', '7,413,650,000')\n('Patient_01.Timepoint_7', '3,746,350,000')\n('Patient_01.Timepoint_7_unmod', '5,798,025,000')\n('Patient_02.Timepoint_1', '1,429,182,500')\n('Patient_02.Timepoint_1_unmod', '5,593,850,000')\n('Patient_02.Timepoint_2', '3,215,465,000')\n('Patient_02.Timepoint_2_unmod', '6,030,800,000')\n"
    }
   ],
   "source": [
    "# for understanding data\n",
    "for data in get_tsv_data(\"./data/data.tsv\"):\n",
    "    print(*list(data)[:50], sep=\"\\n\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self, patient, pepti, intensity):\n",
    "        '''\n",
    "        patient is a list of patient name corresponding to x-asix in intensity\n",
    "        pepti is a list of pepti id corresponsing to y-axis in intensity\n",
    "        intensity is a 2D numpy array what stores intensity data of patient and pepti\n",
    "        '''\n",
    "        self.patient = patient\n",
    "        self.pepti = pepti\n",
    "        self.intensity = intensity \n",
    "\n",
    "    @staticmethod\n",
    "    def intensity_string_to_int(intensity):\n",
    "        if intensity == \"N/A\":\n",
    "            return 0\n",
    "        return int(intensity.replace(',', ''))\n",
    "\n",
    "    @classmethod\n",
    "    def fromFilePath(cls, path, pepti_id_col = 1, start_col = 32):\n",
    "        #count line of file\n",
    "        num_pepti = 0\n",
    "        for _ in open(path): \n",
    "            num_pepti += 1\n",
    "        num_pepti -= 1 # remove header\n",
    "\n",
    "        #open file\n",
    "        with open(path) as tsv:\n",
    "            reader = csv.reader(tsv, dialect=\"excel-tab\")\n",
    "            patient = next(reader)[start_col:] #header after 32 is patient name with time stamp\n",
    "            pepti = [\"\"] * num_pepti\n",
    "            intensity_data = np.empty((num_pepti, len(patient)), int)\n",
    "\n",
    "            for i, line in enumerate(reader):\n",
    "                pepti[i] = line[ pepti_id_col ]\n",
    "                intensity_data[i,:] = np.array([ cls.intensity_string_to_int(l) for l in line[start_col:]])\n",
    "\n",
    "        return cls(patient, pepti, intensity_data)\n",
    "\n",
    "    def get_patient_from_index(self,p_index):\n",
    "        return self.intensity[:,p_index]\n",
    "\n",
    "    def get_patient(self, patient):\n",
    "        p_index = self.patient.index(patient)\n",
    "        return self.get_patient_from_index(p_index)\n",
    "\n",
    "    def get_patient_list(self, patient_list):\n",
    "        re = np.zeros((len(self.pepti), len(patient_list)))\n",
    "        for i, pat in enumerate(patient_list):\n",
    "            re[:,i] = self.get_patient(pat)\n",
    "        return re\n",
    "\n",
    "    def get_pepti_from_index(self,p_index):\n",
    "        return self.intensity[p_index,:]\n",
    "\n",
    "    def get_pepti(self, pepti):\n",
    "        p_index = self.pepti.index(pepti)\n",
    "        return self.get_pepti_from_index(p_index)\n",
    "\n",
    "    def get_pepti_list(self, pepti_list):\n",
    "        re = np.zeros((len(pepti_list), len(self.patient)),int)\n",
    "        for i, pep in enumerate(pepti_list):\n",
    "            re[i,:] = self.get_pepti(pep)\n",
    "        return re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(40921, 672)\n672\n['Patient_01.Timepoint_1', 'Patient_01.Timepoint_1_unmod', 'Patient_01.Timepoint_2', 'Patient_01.Timepoint_2_unmod', 'Patient_01.Timepoint_3', 'Patient_01.Timepoint_3_unmod', 'Patient_01.Timepoint_4', 'Patient_01.Timepoint_4_unmod', 'Patient_01.Timepoint_5', 'Patient_01.Timepoint_5_unmod']\n40921\n['SPLFM+15.995GK', 'EPQVYTLPPSREEM+15.995TK', 'AVM+15.995DDFAAFVEK', 'EFNAETFTFHADIC-33.988TLSEK', 'M+15.995ADEAGSEADHEGTHSTK', 'DVFLGM+15.995FLYEYAR', 'ETEGLRQEM+15.995SK', 'ALTDMPQM+15.995R', 'DTLM+15.995ISR', 'ALTDM+15.995PQM+15.995R']\n"
    }
   ],
   "source": [
    "#loading data\n",
    "data = Data.fromFilePath(\"./data/data.tsv\")\n",
    "\n",
    "#showing what data contains\n",
    "print(data.intensity.shape)\n",
    "\n",
    "print(len(data.patient))\n",
    "print(data.patient[:10])\n",
    "\n",
    "print(len(data.pepti))\n",
    "print(data.pepti[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "40921\n672\n(40921, 10)\n(10, 672)\n"
    }
   ],
   "source": [
    "#testing some get function\n",
    "print(len(data.get_patient('Patient_01.Timepoint_1')))\n",
    "print(len(data.get_pepti('SPLFM+15.995GK')))\n",
    "\n",
    "temp_patient = data.get_patient_list(['Patient_01.Timepoint_1', 'Patient_01.Timepoint_1_unmod', 'Patient_01.Timepoint_2', 'Patient_01.Timepoint_2_unmod', 'Patient_01.Timepoint_3', 'Patient_01.Timepoint_3_unmod', 'Patient_01.Timepoint_4', 'Patient_01.Timepoint_4_unmod', 'Patient_01.Timepoint_5', 'Patient_01.Timepoint_5_unmod'])\n",
    "print(temp_patient.shape)\n",
    "\n",
    "temp_papti = data.get_pepti_list(['SPLFM+15.995GK', 'EPQVYTLPPSREEM+15.995TK', 'AVM+15.995DDFAAFVEK', 'EFNAETFTFHADIC-33.988TLSEK', 'M+15.995ADEAGSEADHEGTHSTK', 'DVFLGM+15.995FLYEYAR', 'ETEGLRQEM+15.995SK', 'ALTDMPQM+15.995R', 'DTLM+15.995ISR', 'ALTDM+15.995PQM+15.995R'])\n",
    "print(temp_papti.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatientDiffLoader(Dataset):\n",
    "    # UNTESTED !!!\n",
    "    def __init__(self, path):\n",
    "        self.data = Data.fromFilePath(path)\n",
    "    def __len__(self):\n",
    "        return len(self.data.patient)\n",
    "\n",
    "    def __getitem__(self, idx, mode=\"same_patient\"):\n",
    "        diff = bool(random.getrandbits(1))\n",
    "        \n",
    "        print(self.data.patient[idx])\n",
    "        pid = int(self.data.patient[idx][8:10])\n",
    "        tp = int(self.data.patient[idx][21])\n",
    "\n",
    "        label = None\n",
    "        data_1 = self.data.get_patient_from_index(idx)\n",
    "        data_2 = None\n",
    "        if diff:\n",
    "            #different class\n",
    "            label = 0.0\n",
    "\n",
    "            #get a differnt pid\n",
    "            diff_pid = -1\n",
    "            while True:\n",
    "                diff_pid = random.randint(1,58) #there is 58 patients? TODO: make sure it's 58\n",
    "                if diff_pid != pid:\n",
    "                    break\n",
    "\n",
    "            #get diff data\n",
    "            random_diff = f\"Patient_{diff_pid:02d}.Timepoint_{random.randint(1,7)}{random.choice(['', '_unmod'])}\"\n",
    "            data_2 = self.data.get_patient( random_diff )\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            #same class\n",
    "            label = 1.0\n",
    "            random_same = f\"Patient_{pid:02d}.Timepoint_{random.randint(1,7)}{random.choice(['','_unmod'])}\"\n",
    "            data_2 = self.data.get_patient( random_same )\n",
    "\n",
    "        return data_1, data_2, torch.from_numpy(np.array([label], dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modified from https://www.kaggle.com/jiangstein/a-very-simple-siamese-network-in-pytorch, for testing data pipline only\n",
    "\n",
    "class SiameseNetwork(nn.Module):# A simple implementation of siamese network, ResNet50 is used, and then connected by three fc layer.\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Linear(40921, 2*32*100*100)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(2*32*100*100, 500)\n",
    "        #self.fc1 = nn.Linear(2*1000, 500)\n",
    "        self.fc2 = nn.Linear(500, 500)\n",
    "        self.fc3 = nn.Linear(500, 2)\n",
    "\n",
    "\n",
    "    def forward(self, input1, input2):#did not know how to let two resnet share the same param.\n",
    "        output1 = self.cnn1(input1)\n",
    "        output1 = output1.view(output1.size()[0], -1)#make it suitable for fc layer.\n",
    "        output2 = self.cnn1(input2)\n",
    "        output2 = output2.view(output2.size()[0], -1)\n",
    "        \n",
    "        output = torch.cat((output1, output2),1)\n",
    "        output = F.relu(self.fc1(output))\n",
    "        output = F.relu(self.fc2(output))\n",
    "        output = self.fc3(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = PatientDiffLoader(\"./data/data.tsv\")\n",
    "loader = DataLoader(full_dataset, shuffle=True, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SiameseNetwork()\n",
    "criterion = nn.CrossEntropyLoss() # use a Classification Cross-Entropy loss\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "loss_val = 0\n",
    "print(\"start\")\n",
    "for batch_id, (d1, d2, label) in enumerate(loader):\n",
    "    optimizer.zero_grad()\n",
    "    output = net.forward(d1, d2)\n",
    "    loss = loss_fn(output, label)\n",
    "    loss_val += loss.item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(batch_id, loss_val, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}